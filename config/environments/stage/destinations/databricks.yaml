# Databricks Destination Configuration (Staging)
destination:
  name: databricks_stage
  type: databricks
  description: "Databricks staging environment"
  environment: stage

  connection:
    server_hostname_secret_key: "DATABRICKS_HOST_STAGE"
    http_path_secret_key: "DATABRICKS_HTTP_PATH_STAGE"
    access_token_secret_key: "DATABRICKS_TOKEN_STAGE"

    catalog: "stage_catalog"
    schema: "raw_data"

    session_configuration:
      "spark.databricks.delta.optimizeWrite.enabled": "true"
      "spark.databricks.delta.autoCompact.enabled": "true"

    timeout: 600
    retry:
      max_attempts: 5
      backoff_factor: 2

  settings:
    table_format: "delta"
    partition_by: ["_extracted_at"]
    cluster_by: []

    write_mode: "append"
    optimize_after_write: true
    vacuum_after_write: true
    vacuum_retention_hours: 168 # 7 days

    schema_evolution: true
    case_sensitive: false

    max_parallel_loads: 8
    batch_size: 50000

  naming:
    prefix: "raw_"
    suffix: ""
    case: "snake_case"

  data_retention:
    enabled: true
    days: 30
