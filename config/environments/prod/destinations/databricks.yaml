# Databricks Destination Configuration (Production)
destination:
  name: databricks_prod
  type: databricks
  description: "Databricks production environment"
  environment: prod

  connection:
    server_hostname_secret_key: "DATABRICKS_HOST_PROD"
    http_path_secret_key: "DATABRICKS_HTTP_PATH_PROD"
    access_token_secret_key: "DATABRICKS_TOKEN_PROD"

    catalog: "prod_catalog"
    schema: "raw_data"

    session_configuration:
      "spark.databricks.delta.optimizeWrite.enabled": "true"
      "spark.databricks.delta.autoCompact.enabled": "true"
      "spark.databricks.delta.properties.dataSkippingNumIndexedCols": "32"

    timeout: 900
    retry:
      max_attempts: 7
      backoff_factor: 3

  settings:
    table_format: "delta"
    partition_by: ["_extracted_at"]
    cluster_by: []

    write_mode: "append"
    optimize_after_write: true
    vacuum_after_write: true
    vacuum_retention_hours: 720 # 30 days

    schema_evolution: true
    case_sensitive: false

    max_parallel_loads: 16
    batch_size: 100000

  naming:
    prefix: "raw_"
    suffix: ""
    case: "snake_case"

  data_retention:
    enabled: true
    days: 365
